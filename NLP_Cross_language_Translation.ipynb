{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJPojEfoHeBPoOQTmvEXnK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eshandutta23/Cross-Language-Translation-Tool-NLP-Project-/blob/main/NLP_Cross_language_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/Multi_language_data.csv\")\n",
        "\n",
        "# Show all rows (removes truncation)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "# Display the full DataFrame\n",
        "df"
      ],
      "metadata": {
        "id": "L7C2G0f_lgl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets sacrebleu sentencepiece\n"
      ],
      "metadata": {
        "id": "QAysylL_r-sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import MarianTokenizer, MarianMTModel, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Multi_language_data.csv\")\n",
        "\n",
        "# Filter for one language pair: English to Hindi\n",
        "df = df[df[\"target_language_code\"] == \"hi_IN\"]\n",
        "\n",
        "# Rename columns for HuggingFace dataset\n",
        "df = df.rename(columns={\"source\": \"translation_source\", \"target\": \"translation_target\"})\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Load MarianMT model and tokenizer\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "# Tokenization\n",
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer(examples[\"translation_source\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"translation_target\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n"
      ],
      "metadata": {
        "id": "01vrB4FvsO-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./marian-en-hi-model\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True  # Only works if it is running on GPU with float16 support\n",
        ")\n"
      ],
      "metadata": {
        "id": "b2jaWyLLsXnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Supported translation directions and models\n",
        "LANGUAGE_MODELS = {\n",
        "    \"English to Hindi\": \"Helsinki-NLP/opus-mt-en-hi\",\n",
        "    \"Hindi to English\": \"Helsinki-NLP/opus-mt-hi-en\",\n",
        "\n",
        "    \"English to German\": \"Helsinki-NLP/opus-mt-en-de\",\n",
        "    \"German to English\": \"Helsinki-NLP/opus-mt-de-en\",\n",
        "\n",
        "    \"English to Spanish\": \"Helsinki-NLP/opus-mt-en-es\",\n",
        "    \"Spanish to English\": \"Helsinki-NLP/opus-mt-es-en\",\n",
        "\n",
        "    \"English to French\": \"Helsinki-NLP/opus-mt-en-fr\",\n",
        "    \"French to English\": \"Helsinki-NLP/opus-mt-fr-en\",\n",
        "\n",
        "    \"English to Kannada\": \"Helsinki-NLP/opus-mt-en-kn\",\n",
        "    \"Kannada to English\": \"Helsinki-NLP/opus-mt-kn-en\"\n",
        "}\n",
        "\n",
        "# Translation function with forced \"नमस्ते\" for Hindi greeting\n",
        "def translate_text(text, direction):\n",
        "    model_name = LANGUAGE_MODELS[direction]\n",
        "\n",
        "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "    model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "    inputs = tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    output = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "\n",
        "    # Force prepend \"नमस्ते\" if the input contains a greeting\n",
        "    if direction == \"English to Hindi\":\n",
        "        greetings = [\"hello\", \"hi\", \"hey\"]\n",
        "        if any(greet in text.lower() for greet in greetings):\n",
        "            if \"नमस्ते\" not in output:\n",
        "                output = \"नमस्ते \" + output.lstrip(\"।\").lstrip(\", \")\n",
        "\n",
        "    return output\n",
        "\n",
        "# Gradio UI\n",
        "gr.Interface(\n",
        "    fn=translate_text,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter Text\"),\n",
        "        gr.Dropdown(choices=list(LANGUAGE_MODELS.keys()), label=\"Translation Direction\")\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"Cross Language Translation Tool\",\n",
        "    description=\"Translate between different languages\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "id": "k7Q5sxoOsinm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer, MBartForConditionalGeneration, MBart50TokenizerFast\n"
      ],
      "metadata": {
        "id": "EfdsUHrYXyrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MarianMT (English to Hindi)\n",
        "marian_model_name = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "marian_tokenizer = MarianTokenizer.from_pretrained(marian_model_name)\n",
        "marian_model = MarianMTModel.from_pretrained(marian_model_name)\n",
        "\n",
        "# mBART (multilingual: must specify lang codes)\n",
        "mbart_model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "mbart_tokenizer = MBart50TokenizerFast.from_pretrained(mbart_model_name)\n",
        "mbart_model = MBartForConditionalGeneration.from_pretrained(mbart_model_name)\n"
      ],
      "metadata": {
        "id": "Ak3zuB90X0N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def marian_translate(text):\n",
        "    inputs = marian_tokenizer([text], return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    translated = marian_model.generate(**inputs)\n",
        "    return marian_tokenizer.decode(translated[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "wTPG-U7bYgW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mbart_translate(text):\n",
        "    mbart_tokenizer.src_lang = \"en_XX\"\n",
        "    encoded = mbart_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    generated_tokens = mbart_model.generate(\n",
        "        **encoded,\n",
        "        forced_bos_token_id=mbart_tokenizer.lang_code_to_id[\"hi_IN\"]\n",
        "    )\n",
        "    return mbart_tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "O1M1dKf1YhyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation based on Qulatitative Evaluation\n",
        "import gradio as gr\n",
        "\n",
        "def compare_models(text):\n",
        "    marian_out = marian_translate(text)\n",
        "    mbart_out = mbart_translate(text)\n",
        "    return marian_out, mbart_out\n",
        "\n",
        "gr.Interface(\n",
        "    fn=compare_models,\n",
        "    inputs=gr.Textbox(label=\"Enter text in English\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"MarianMT Output\"),\n",
        "        gr.Textbox(label=\"mBART Output\")\n",
        "    ],\n",
        "    title=\"MarianMT vs mBART: English to Hindi Translator\",\n",
        "    description=\"Compare translations between MarianMT and mBART for the same input.\"\n",
        ").launch()\n"
      ],
      "metadata": {
        "id": "wU2Ixs-ZYkgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "bleu = load_metric(\"sacrebleu\")\n",
        "\n",
        "predictions = [\"He goes to school.\"]\n",
        "references = [[\"He is going to school.\"]]\n",
        "\n",
        "bleu_score = bleu.compute(predictions=predictions, references=references)\n",
        "print(\"BLEU Score:\", bleu_score[\"score\"])\n",
        "print(\"The model produces accurate and fluent translations and is well fine tuned\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2AZi_QkrS5m0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}